{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySparkInstall_Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darstsharon/Aliens-Are-Real/blob/master/PySparkInstall_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALPAPTRXm-qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM3bRx74nAst",
        "colab_type": "text"
      },
      "source": [
        "1. Go to \n",
        "colab.research.google.com\n",
        "\n",
        "2. \n",
        "!apt-get install openjdk-8-jdk-headless -qq\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz21jBwsnBm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m6YxtH1nEfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOknmnXUnH6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoTaP8KZnJiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4OCfawonLBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b5Ghv-_nOds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkFiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "533t-2-fosbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"example\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dSc0bfmoBJW",
        "colab_type": "code",
        "outputId": "a07979f4-1573-41d1-9f1f-807c48521572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/food.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"food.csv\"), sep=\",\", header=True)\n",
        "df.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|   food|price|\n",
            "+-------+-----+\n",
            "|  pizza|    0|\n",
            "|  sushi|   12|\n",
            "|chinese|   10|\n",
            "+-------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpDW23aBoMCu",
        "colab_type": "code",
        "outputId": "be526061-0234-4ab1-ae84-b8f87830022c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- food: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt3dOT-Ro8q-",
        "colab_type": "code",
        "outputId": "aa136da7-3f2f-42b4-a8c7-a0a8b3d68ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# count rows in dataframe\n",
        "df.count()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieqx3ixapGQ3",
        "colab_type": "code",
        "outputId": "adb59d8e-f656-4937-862c-2cfeab302bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df2 = df.withColumn(\"static_column\", lit(\"hellow world\"))\n",
        "df2.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-------------+\n",
            "|   food|price|static_column|\n",
            "+-------+-----+-------------+\n",
            "|  pizza|    0| hellow world|\n",
            "|  sushi|   12| hellow world|\n",
            "|chinese|   10| hellow world|\n",
            "+-------+-----+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohOPCCXzpXog",
        "colab_type": "code",
        "outputId": "05fe7c58-a5c9-46ad-9b81-e880f2ae4e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# user-define function\n",
        "from pyspark.sql.functions import udf\n",
        "df3 = df2.withColumn(\"number_of_characters\", udf(lambda x: len(x))(\"food\"))\n",
        "df3.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-------------+--------------------+\n",
            "|   food|price|static_column|number_of_characters|\n",
            "+-------+-----+-------------+--------------------+\n",
            "|  pizza|    0| hellow world|                   5|\n",
            "|  sushi|   12| hellow world|                   5|\n",
            "|chinese|   10| hellow world|                   7|\n",
            "+-------+-----+-------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3LE_V9Tp9Sl",
        "colab_type": "code",
        "outputId": "8d0122ce-6e03-44ab-80be-d565bbbe789a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# refactored\n",
        "count_characters = udf(lambda x: len(x))\n",
        "df3 = df2.withColumn(\"number_of_characters_refactored\", count_characters(\"food\"))\n",
        "df3.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+-------------+-------------------------------+\n",
            "|   food|price|static_column|number_of_characters_refactored|\n",
            "+-------+-----+-------------+-------------------------------+\n",
            "|  pizza|    0| hellow world|                              5|\n",
            "|  sushi|   12| hellow world|                              5|\n",
            "|chinese|   10| hellow world|                              7|\n",
            "+-------+-----+-------------+-------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv3k8MNk4FJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4b36f142-f10c-4233-823c-feea7a7607f8"
      },
      "source": [
        "!ls ."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mysql-connector-java-8.0.16.jar  spark-2.4.3-bin-hadoop2.7.tgz\n",
            "sample_data\t\t\t spark-2.4.3-bin-hadoop2.7.tgz.1\n",
            "spark-2.4.3-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNQnxj4Pqzbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp mysql-connector-java-8.0.16.jar spark-2.4.3-bin-hadoop2.7/jars/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvmD3WBz5GKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7lGC3xr50jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}